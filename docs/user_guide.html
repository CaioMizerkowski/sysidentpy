


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>User Guide &mdash; SysIdentPy</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="_static/jquery.fancybox.min.css" type="text/css" />
  
    <link rel="stylesheet" href="_static/glpi.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="SysIdentPy" href="index.html"/>
        <link rel="next" title="Contributing" href="dev_guide.html"/>
        <link rel="prev" title="A brief introduction to NARMAX models." href="introduction_to_narmax.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> sysidentpy
          

          
          </a>

          
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Install Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="introduction_to_narmax.html">A brief introduction to NARMAX models.</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#presenting-main-functionality">Presenting main functionality</a></li>
<li class="toctree-l2"><a class="reference internal" href="#generating-1-input-1-output-sample-data">Generating 1 input 1 output sample data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-data-is-generated-by-simulating-the-following-model">The data is generated by simulating the following model:</a></li>
<li class="toctree-l3"><a class="reference internal" href="#to-obtain-a-narmax-model-we-have-to-choose-some-values-e-g-the-nonlinearity-degree-non-degree-the-maximum-lag-for-the-inputs-and-output-xlag-and-ylag">To obtain a NARMAX model we have to choose some values, <em>e.g</em>, the nonlinearity degree (<em>non_degree</em>), the maximum lag for the inputs and output (<em>xlag</em> and <em>ylag</em>).</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#in-addition-you-can-select-the-information-criteria-to-be-used-with-the-error-reduction-ratio-to-select-the-model-order-and-the-method-to-estimate-the-model-paramaters">In addition, you can select the information criteria to be used with the Error Reduction Ratio to select the model order and the method to estimate the model paramaters:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#the-fit-method-executes-the-error-reduction-ratio-algorithm-using-househoulder-reflection-to-select-the-model-structure">The <em>fit</em> method executes the Error Reduction Ratio algorithm using Househoulder reflection to select the model structure.</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-predict-method-is-use-to-generate-the-predictions-for-now-we-only-support-free-run-simulation-also-known-as-infinity-steps-ahead-soon-will-let-the-user-define-a-one-step-ahead-or-k-step-ahead-prediction">The <em>predict</em> method is use to generate the predictions. For now we only support <em>free run simulation</em> (also known as <em>infinity steps ahead</em>). Soon will let the user define a <em>one-step ahead</em> or <em>k-step ahead</em> prediction.</a></li>
<li class="toctree-l3"><a class="reference internal" href="#in-this-example-we-use-the-root-relative-squared-error-metric-because-it-is-often-used-in-system-idenfication-more-metrics-and-information-about-it-can-be-found-on-documentation">In this example we use the <em>root_relative_squared_error</em> metric because it is often used in System Idenfication. More metrics and information about it can be found on documentation.</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-object-results-return-the-selected-model-regressors-the-estimated-parameters-and-the-err-values-as-shown-below-the-algorithm-detect-the-exact-model-that-was-used-for-simulate-the-data"><em>model_object.results</em> return the selected model regressors, the estimated parameters and the ERR values. As shown below, the algorithm detect the exact model that was used for simulate the data.</a></li>
<li class="toctree-l3"><a class="reference internal" href="#in-addition-you-can-access-the-residuals-and-plot-result-methods-to-take-a-look-at-the-prediction-and-two-residual-analysis-the-extras-and-lam-values-below-contain-another-residues-analysis-so-you-can-plot-it-mannualy-this-method-will-be-improved-soon">In addition, you can access the <em>residuals</em> and <em>plot_result</em> methods to take a look at the prediction and two residual analysis. The <em>extras</em> and <em>lam</em> values below contain another residues analysis so you can plot it mannualy. This method will be improved soon.</a></li>
<li class="toctree-l3"><a class="reference internal" href="#in-the-example-above-we-let-the-number-of-terms-to-compose-the-final-model-to-be-defined-as-the-minimum-value-of-the-information-criteria-once-you-ran-the-algorithm-and-choose-the-best-number-of-parameters-you-can-turn-order-selection-to-false-and-set-the-n-terms-value-3-in-this-example-here-we-have-a-small-dataset-but-in-bigger-data-this-can-be-critical-because-running-information-criteria-algorithm-is-more-computational-expensive-since-we-already-know-the-best-number-of-regressor-we-set-n-terms-and-we-get-the-same-result">In the example above we let the number of terms to compose the final model to be defined as the minimum value of the information criteria. Once you ran the algorithm and choose the best number of parameters, you can turn <em>order_selection</em> to <em>False</em> and set the <em>n_terms</em> value (3 in this example). Here we have a small dataset, but in bigger data this can be critical because running information criteria algorithm is more computational expensive. Since we already know the best number of regressor, we set <em>n_terms</em> and we get the same result.</a></li>
<li class="toctree-l3"><a class="reference internal" href="#however-this-is-not-only-critical-because-computational-eficiency-in-many-situation-the-minimum-value-of-the-information-criteria-can-lead-to-overfiting-in-some-cases-the-diference-between-choosing-a-model-with-30-regressors-or-10-is-minimal-so-you-can-take-the-model-with-10-terms-without-loosing-accuracy">However, this is not only critical because computational eficiency. In many situation, the minimum value of the information criteria can lead to overfiting. In some cases, the diference between choosing a model with 30 regressors or 10 is minimal, so you can take the model with 10 terms without loosing accuracy.</a></li>
<li class="toctree-l3"><a class="reference internal" href="#in-the-following-we-use-info-values-to-plot-the-information-criteria-values-as-you-can-see-the-minimum-value-relies-where-xaxis-5">In the following we use <em>info_values</em> to plot the information criteria values. As you can see, the minimum value relies where <span class="math notranslate nohighlight">\(xaxis = 5\)</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#important-note">Important Note:</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#here-we-are-creating-random-samples-with-white-noise-and-letting-the-algorithm-choose-the-number-of-terms-based-on-the-minimum-value-of-information-criteria-this-is-not-the-best-approach-in-system-identification-but-serves-as-a-simple-example-the-information-criteria-must-be-used-as-an-auxiliary-tool-to-select-n-terms-plot-the-information-values-to-help-you-on-that">Here we are creating random samples with white noise and letting the algorithm choose the number of terms based on the minimum value of information criteria. This is not the best approach in System Identification, but serves as a simple example. The information criteria must be used as an <strong>auxiliary tool</strong> to select <em>n_terms</em>. Plot the information values to help you on that!</a></li>
<li class="toctree-l3"><a class="reference internal" href="#if-you-run-the-example-above-several-times-you-might-find-some-cases-where-the-algorithm-choose-only-the-first-two-regressors-or-four-depending-on-the-information-criteria-method-selected-this-is-because-the-minimum-value-of-information-criteria-depends-on-residual-variance-affected-by-noise-and-have-some-limitations-in-nonlinear-scenarios-however-if-you-check-the-err-values-robust-to-noise-you-will-see-that-the-err-is-ordering-the-regressors-in-the-correct-way">If you run the example above several times you might find some cases where the algorithm choose only the first two regressors, or four (depending on the information criteria method selected). This is because the minimum value of information criteria depends on residual variance (affected by noise) and have some limitations in nonlinear scenarios. However, if you check the ERR values (robust to noise) you will see that the ERR is ordering the regressors in the correct way!</a></li>
<li class="toctree-l3"><a class="reference internal" href="#we-have-some-examples-on-information-criteria-notebook">We have some examples on <em>information_criteria</em> notebook!</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-n-info-values-limits-the-number-of-regressors-to-apply-the-information-criteria-we-choose-n-y-n-x-ell-2-so-the-candidate-regressor-is-a-list-of-15-regressors-we-can-set-n-info-values-15-and-see-the-information-values-for-all-regressors-this-option-can-save-some-amount-of-computational-resources-when-dealing-with-multiples-inputs-and-large-datasets">The <em>n_info_values</em> limits the number of regressors to apply the information criteria. We choose <span class="math notranslate nohighlight">\(n_y = n_x = \ell = 2\)</span>, so the candidate regressor is a list of 15 regressors. We can set <em>n_info_values = 15</em> and see the information values for all regressors. This option can save some amount of computational resources when dealing with multiples inputs and large datasets.</a></li>
<li class="toctree-l3"><a class="reference internal" href="#now-running-without-executing-information-criteria-methods-setting-the-n-terms-because-we-already-know-the-optimal-number-of-regressors">Now running without executing information criteria methods (setting the <em>n_terms</em>) because we already know the optimal number of regressors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#you-can-acess-some-extra-information-like-the-list-of-all-candidate-regressors">You can acess some extra information like the list of all candidate regressors</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dev_guide.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks.html">Jupyter notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html">Codes</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html#module-sysidentpy.base">sysidentpy base</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html#sysidentpy-main">sysidentpy main</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html#module-sysidentpy.residues.residues_correlation">sysidentpy residues</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html#module-sysidentpy.metrics._regression">sysidentpy metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html#module-sysidentpy.parameter_estimation.estimators">sysidentpy estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html#module-sysidentpy.utils._check_arrays">sysidentpy utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html#module-sysidentpy.utils.generate_data">sysidentpy generate data</a></li>
<li class="toctree-l1"><a class="reference internal" href="code.html#indices-and-tables">Indices and tables</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">sysidentpy</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>User Guide</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/user_guide.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <div class="rst-breadcrumbs-buttons" role="navigation" aria-label="breadcrumb navigation">
      
        <a href="dev_guide.html" class="btn btn-neutral float-right" title="Contributing" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="introduction_to_narmax.html" class="btn btn-neutral" title="A brief introduction to NARMAX models." accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
  </div>
  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="user-guide">
<h1>User Guide<a class="headerlink" href="#user-guide" title="Permalink to this headline">¶</a></h1>
<div class="section" id="presenting-main-functionality">
<h2>Presenting main functionality<a class="headerlink" href="#presenting-main-functionality" title="Permalink to this headline">¶</a></h2>
<p>Example created by Wilson Rocha Lacerda Junior</p>
<p>Here we import the NARMAX model, the metric for model evaluation and the
methods to generate sample data for tests. Also, we import pandas for
specific usage.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sysidentpy.polynomial_basis</span> <span class="kn">import</span> <span class="n">PolynomialNarmax</span>
<span class="kn">from</span> <span class="nn">sysidentpy.metrics</span> <span class="kn">import</span> <span class="n">root_relative_squared_error</span>
<span class="kn">from</span> <span class="nn">sysidentpy.utils.generate_data</span> <span class="kn">import</span> <span class="n">get_miso_data</span><span class="p">,</span> <span class="n">get_siso_data</span>
</pre></div>
</div>
</div>
<div class="section" id="generating-1-input-1-output-sample-data">
<h2>Generating 1 input 1 output sample data<a class="headerlink" href="#generating-1-input-1-output-sample-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-data-is-generated-by-simulating-the-following-model">
<h3>The data is generated by simulating the following model:<a class="headerlink" href="#the-data-is-generated-by-simulating-the-following-model" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(y_k = 0.2y_{k-1} + 0.1y_{k-1}x_{k-1} + 0.9x_{k-1} + e_{k}\)</span></p>
<p>If <em>colored_noise</em> is set to True:</p>
<p><span class="math notranslate nohighlight">\(e_{k} = 0.8\nu_{k-1} + \nu_{k}\)</span></p>
<p>where <span class="math notranslate nohighlight">\(x\)</span> is a uniformly distributed random variable and
<span class="math notranslate nohighlight">\(\nu\)</span> is a gaussian distributed variable with <span class="math notranslate nohighlight">\(\mu=0\)</span> and
<span class="math notranslate nohighlight">\(\sigma=0.1\)</span></p>
<p>In the next example we will generate a data with 1000 samples with white
noise and selecting 90% of the data to train the model.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">get_siso_data</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                                   <span class="n">colored_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                   <span class="n">sigma</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                                                   <span class="n">train_percentage</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="to-obtain-a-narmax-model-we-have-to-choose-some-values-e-g-the-nonlinearity-degree-non-degree-the-maximum-lag-for-the-inputs-and-output-xlag-and-ylag">
<h3>To obtain a NARMAX model we have to choose some values, <em>e.g</em>, the nonlinearity degree (<em>non_degree</em>), the maximum lag for the inputs and output (<em>xlag</em> and <em>ylag</em>).<a class="headerlink" href="#to-obtain-a-narmax-model-we-have-to-choose-some-values-e-g-the-nonlinearity-degree-non-degree-the-maximum-lag-for-the-inputs-and-output-xlag-and-ylag" title="Permalink to this headline">¶</a></h3>
<div class="section" id="in-addition-you-can-select-the-information-criteria-to-be-used-with-the-error-reduction-ratio-to-select-the-model-order-and-the-method-to-estimate-the-model-paramaters">
<h4>In addition, you can select the information criteria to be used with the Error Reduction Ratio to select the model order and the method to estimate the model paramaters:<a class="headerlink" href="#in-addition-you-can-select-the-information-criteria-to-be-used-with-the-error-reduction-ratio-to-select-the-model-order-and-the-method-to-estimate-the-model-paramaters" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>Information Criteria: aic, bic, lilc, fpe</p></li>
<li><p>Parameter Estimation: least_squares, total_least_squares,
recursive_least_squares, least_mean_squres and many other (see the
docs)</p></li>
</ul>
<p>The <em>n_terms</em> values is optional. It refer to the number of terms to
inclued in the final model. You can set this value based on the
information criteria (see below) or based on priori information about
the model struture. The default value is <em>n_terms=None</em>, so the
algorithm will choose the minimum value reached by the information
criteria.</p>
<p>To use information criteria you have to set <em>order_selection=True</em>. You
can also select <em>n_info_values</em> (default = 15).</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">PolynomialNarmax</span><span class="p">(</span><span class="n">non_degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                         <span class="n">order_selection</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">n_info_values</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                         <span class="n">extended_least_squares</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                         <span class="n">ylag</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">xlag</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                         <span class="n">info_criteria</span><span class="o">=</span><span class="s1">&#39;aic&#39;</span><span class="p">,</span>
                         <span class="n">estimator</span><span class="o">=</span><span class="s1">&#39;least_squares&#39;</span><span class="p">,</span>
                         <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="the-fit-method-executes-the-error-reduction-ratio-algorithm-using-househoulder-reflection-to-select-the-model-structure">
<h3>The <em>fit</em> method executes the Error Reduction Ratio algorithm using Househoulder reflection to select the model structure.<a class="headerlink" href="#the-fit-method-executes-the-error-reduction-ratio-algorithm-using-househoulder-reflection-to-select-the-model-structure" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">sysidentpy</span><span class="o">.</span><span class="n">polynomial_basis</span><span class="o">.</span><span class="n">narmax</span><span class="o">.</span><span class="n">PolynomialNarmax</span> <span class="n">at</span> <span class="mh">0x7f332d0cc490</span><span class="o">&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="the-predict-method-is-use-to-generate-the-predictions-for-now-we-only-support-free-run-simulation-also-known-as-infinity-steps-ahead-soon-will-let-the-user-define-a-one-step-ahead-or-k-step-ahead-prediction">
<h3>The <em>predict</em> method is use to generate the predictions. For now we only support <em>free run simulation</em> (also known as <em>infinity steps ahead</em>). Soon will let the user define a <em>one-step ahead</em> or <em>k-step ahead</em> prediction.<a class="headerlink" href="#the-predict-method-is-use-to-generate-the-predictions-for-now-we-only-support-free-run-simulation-also-known-as-infinity-steps-ahead-soon-will-let-the-user-define-a-one-step-ahead-or-k-step-ahead-prediction" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="in-this-example-we-use-the-root-relative-squared-error-metric-because-it-is-often-used-in-system-idenfication-more-metrics-and-information-about-it-can-be-found-on-documentation">
<h3>In this example we use the <em>root_relative_squared_error</em> metric because it is often used in System Idenfication. More metrics and information about it can be found on documentation.<a class="headerlink" href="#in-this-example-we-use-the-root-relative-squared-error-metric-because-it-is-often-used-in-system-idenfication-more-metrics-and-information-about-it-can-be-found-on-documentation" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rrse</span> <span class="o">=</span> <span class="n">root_relative_squared_error</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rrse</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">0.0018758031321337446</span>
</pre></div>
</div>
</div>
<div class="section" id="model-object-results-return-the-selected-model-regressors-the-estimated-parameters-and-the-err-values-as-shown-below-the-algorithm-detect-the-exact-model-that-was-used-for-simulate-the-data">
<h3><em>model_object.results</em> return the selected model regressors, the estimated parameters and the ERR values. As shown below, the algorithm detect the exact model that was used for simulate the data.<a class="headerlink" href="#model-object-results-return-the-selected-model-regressors-the-estimated-parameters-and-the-err-values-as-shown-below-the-algorithm-detect-the-exact-model-that-was-used-for-simulate-the-data" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">(</span><span class="n">err_precision</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                     <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;dec&#39;</span><span class="p">),</span>
                       <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Regressors&#39;</span><span class="p">,</span> <span class="s1">&#39;Parameters&#39;</span><span class="p">,</span> <span class="s1">&#39;ERR&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Regressors</span> <span class="n">Parameters</span>         <span class="n">ERR</span>
<span class="mi">0</span>        <span class="n">u1</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>     <span class="mf">0.9001</span>  <span class="mf">0.95750813</span>
<span class="mi">1</span>         <span class="n">y</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>     <span class="mf">0.2000</span>  <span class="mf">0.03916822</span>
<span class="mi">2</span>  <span class="n">u1</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="n">y</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>     <span class="mf">0.1003</span>  <span class="mf">0.00332022</span>
</pre></div>
</div>
</div>
<div class="section" id="in-addition-you-can-access-the-residuals-and-plot-result-methods-to-take-a-look-at-the-prediction-and-two-residual-analysis-the-extras-and-lam-values-below-contain-another-residues-analysis-so-you-can-plot-it-mannualy-this-method-will-be-improved-soon">
<h3>In addition, you can access the <em>residuals</em> and <em>plot_result</em> methods to take a look at the prediction and two residual analysis. The <em>extras</em> and <em>lam</em> values below contain another residues analysis so you can plot it mannualy. This method will be improved soon.<a class="headerlink" href="#in-addition-you-can-access-the-residuals-and-plot-result-methods-to-take-a-look-at-the-prediction-and-two-residual-analysis-the-extras-and-lam-values-below-contain-another-residues-analysis-so-you-can-plot-it-mannualy-this-method-will-be-improved-soon" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ee</span><span class="p">,</span> <span class="n">ex</span><span class="p">,</span> <span class="n">extras</span><span class="p">,</span> <span class="n">lam</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">residuals</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">plot_result</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="n">ee</span><span class="p">,</span> <span class="n">ex</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/output_16_0.svg" src="_images/output_16_0.svg" /></div>
<div class="section" id="in-the-example-above-we-let-the-number-of-terms-to-compose-the-final-model-to-be-defined-as-the-minimum-value-of-the-information-criteria-once-you-ran-the-algorithm-and-choose-the-best-number-of-parameters-you-can-turn-order-selection-to-false-and-set-the-n-terms-value-3-in-this-example-here-we-have-a-small-dataset-but-in-bigger-data-this-can-be-critical-because-running-information-criteria-algorithm-is-more-computational-expensive-since-we-already-know-the-best-number-of-regressor-we-set-n-terms-and-we-get-the-same-result">
<h3>In the example above we let the number of terms to compose the final model to be defined as the minimum value of the information criteria. Once you ran the algorithm and choose the best number of parameters, you can turn <em>order_selection</em> to <em>False</em> and set the <em>n_terms</em> value (3 in this example). Here we have a small dataset, but in bigger data this can be critical because running information criteria algorithm is more computational expensive. Since we already know the best number of regressor, we set <em>n_terms</em> and we get the same result.<a class="headerlink" href="#in-the-example-above-we-let-the-number-of-terms-to-compose-the-final-model-to-be-defined-as-the-minimum-value-of-the-information-criteria-once-you-ran-the-algorithm-and-choose-the-best-number-of-parameters-you-can-turn-order-selection-to-false-and-set-the-n-terms-value-3-in-this-example-here-we-have-a-small-dataset-but-in-bigger-data-this-can-be-critical-because-running-information-criteria-algorithm-is-more-computational-expensive-since-we-already-know-the-best-number-of-regressor-we-set-n-terms-and-we-get-the-same-result" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="however-this-is-not-only-critical-because-computational-eficiency-in-many-situation-the-minimum-value-of-the-information-criteria-can-lead-to-overfiting-in-some-cases-the-diference-between-choosing-a-model-with-30-regressors-or-10-is-minimal-so-you-can-take-the-model-with-10-terms-without-loosing-accuracy">
<h3>However, this is not only critical because computational eficiency. In many situation, the minimum value of the information criteria can lead to overfiting. In some cases, the diference between choosing a model with 30 regressors or 10 is minimal, so you can take the model with 10 terms without loosing accuracy.<a class="headerlink" href="#however-this-is-not-only-critical-because-computational-eficiency-in-many-situation-the-minimum-value-of-the-information-criteria-can-lead-to-overfiting-in-some-cases-the-diference-between-choosing-a-model-with-30-regressors-or-10-is-minimal-so-you-can-take-the-model-with-10-terms-without-loosing-accuracy" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="in-the-following-we-use-info-values-to-plot-the-information-criteria-values-as-you-can-see-the-minimum-value-relies-where-xaxis-5">
<h3>In the following we use <em>info_values</em> to plot the information criteria values. As you can see, the minimum value relies where <span class="math notranslate nohighlight">\(xaxis = 5\)</span><a class="headerlink" href="#in-the-following-we-use-info-values-to-plot-the-information-criteria-values-as-you-can-see-the-minimum-value-relies-where-xaxis-5" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">n_info_values</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">info_values</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;n_terms&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Information Criteria&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;Information Criteria&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/output_18_1.svg" src="_images/output_18_1.svg" /></div>
</div>
<div class="section" id="important-note">
<h2>Important Note:<a class="headerlink" href="#important-note" title="Permalink to this headline">¶</a></h2>
<div class="section" id="here-we-are-creating-random-samples-with-white-noise-and-letting-the-algorithm-choose-the-number-of-terms-based-on-the-minimum-value-of-information-criteria-this-is-not-the-best-approach-in-system-identification-but-serves-as-a-simple-example-the-information-criteria-must-be-used-as-an-auxiliary-tool-to-select-n-terms-plot-the-information-values-to-help-you-on-that">
<h3>Here we are creating random samples with white noise and letting the algorithm choose the number of terms based on the minimum value of information criteria. This is not the best approach in System Identification, but serves as a simple example. The information criteria must be used as an <strong>auxiliary tool</strong> to select <em>n_terms</em>. Plot the information values to help you on that!<a class="headerlink" href="#here-we-are-creating-random-samples-with-white-noise-and-letting-the-algorithm-choose-the-number-of-terms-based-on-the-minimum-value-of-information-criteria-this-is-not-the-best-approach-in-system-identification-but-serves-as-a-simple-example-the-information-criteria-must-be-used-as-an-auxiliary-tool-to-select-n-terms-plot-the-information-values-to-help-you-on-that" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="if-you-run-the-example-above-several-times-you-might-find-some-cases-where-the-algorithm-choose-only-the-first-two-regressors-or-four-depending-on-the-information-criteria-method-selected-this-is-because-the-minimum-value-of-information-criteria-depends-on-residual-variance-affected-by-noise-and-have-some-limitations-in-nonlinear-scenarios-however-if-you-check-the-err-values-robust-to-noise-you-will-see-that-the-err-is-ordering-the-regressors-in-the-correct-way">
<h3>If you run the example above several times you might find some cases where the algorithm choose only the first two regressors, or four (depending on the information criteria method selected). This is because the minimum value of information criteria depends on residual variance (affected by noise) and have some limitations in nonlinear scenarios. However, if you check the ERR values (robust to noise) you will see that the ERR is ordering the regressors in the correct way!<a class="headerlink" href="#if-you-run-the-example-above-several-times-you-might-find-some-cases-where-the-algorithm-choose-only-the-first-two-regressors-or-four-depending-on-the-information-criteria-method-selected-this-is-because-the-minimum-value-of-information-criteria-depends-on-residual-variance-affected-by-noise-and-have-some-limitations-in-nonlinear-scenarios-however-if-you-check-the-err-values-robust-to-noise-you-will-see-that-the-err-is-ordering-the-regressors-in-the-correct-way" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="we-have-some-examples-on-information-criteria-notebook">
<h3>We have some examples on <em>information_criteria</em> notebook!<a class="headerlink" href="#we-have-some-examples-on-information-criteria-notebook" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="the-n-info-values-limits-the-number-of-regressors-to-apply-the-information-criteria-we-choose-n-y-n-x-ell-2-so-the-candidate-regressor-is-a-list-of-15-regressors-we-can-set-n-info-values-15-and-see-the-information-values-for-all-regressors-this-option-can-save-some-amount-of-computational-resources-when-dealing-with-multiples-inputs-and-large-datasets">
<h3>The <em>n_info_values</em> limits the number of regressors to apply the information criteria. We choose <span class="math notranslate nohighlight">\(n_y = n_x = \ell = 2\)</span>, so the candidate regressor is a list of 15 regressors. We can set <em>n_info_values = 15</em> and see the information values for all regressors. This option can save some amount of computational resources when dealing with multiples inputs and large datasets.<a class="headerlink" href="#the-n-info-values-limits-the-number-of-regressors-to-apply-the-information-criteria-we-choose-n-y-n-x-ell-2-so-the-candidate-regressor-is-a-list-of-15-regressors-we-can-set-n-info-values-15-and-see-the-information-values-for-all-regressors-this-option-can-save-some-amount-of-computational-resources-when-dealing-with-multiples-inputs-and-large-datasets" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">PolynomialNarmax</span><span class="p">(</span><span class="n">non_degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                         <span class="n">order_selection</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">n_info_values</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                         <span class="n">extended_least_squares</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                         <span class="n">ylag</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">xlag</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                         <span class="n">info_criteria</span><span class="o">=</span><span class="s1">&#39;aic&#39;</span><span class="p">,</span>
                         <span class="n">estimator</span><span class="o">=</span><span class="s1">&#39;least_squares&#39;</span><span class="p">,</span>
                         <span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">n_info_values</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">info_values</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;n_terms&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Information Criteria&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;Information Criteria&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/output_21_1.svg" src="_images/output_21_1.svg" /></div>
<div class="section" id="now-running-without-executing-information-criteria-methods-setting-the-n-terms-because-we-already-know-the-optimal-number-of-regressors">
<h3>Now running without executing information criteria methods (setting the <em>n_terms</em>) because we already know the optimal number of regressors<a class="headerlink" href="#now-running-without-executing-information-criteria-methods-setting-the-n-terms-because-we-already-know-the-optimal-number-of-regressors" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">PolynomialNarmax</span><span class="p">(</span><span class="n">non_degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                         <span class="c1"># order_selection=True,</span>
                         <span class="n">n_terms</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                         <span class="c1"># n_info_values=15,</span>
                         <span class="n">extended_least_squares</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                         <span class="n">ylag</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">xlag</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                         <span class="n">info_criteria</span><span class="o">=</span><span class="s1">&#39;aic&#39;</span><span class="p">,</span>
                         <span class="n">estimator</span><span class="o">=</span><span class="s1">&#39;least_squares&#39;</span><span class="p">,</span>
                         <span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
<span class="n">rrse</span> <span class="o">=</span> <span class="n">root_relative_squared_error</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;rrse: &#39;</span><span class="p">,</span> <span class="n">rrse</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">(</span><span class="n">err_precision</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                     <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;dec&#39;</span><span class="p">),</span>
                       <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Regressors&#39;</span><span class="p">,</span> <span class="s1">&#39;Parameters&#39;</span><span class="p">,</span> <span class="s1">&#39;ERR&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rrse</span><span class="p">:</span>  <span class="mf">0.0018758031321337446</span>

       <span class="n">Regressors</span> <span class="n">Parameters</span>         <span class="n">ERR</span>
<span class="mi">0</span>        <span class="n">u1</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>     <span class="mf">0.9001</span>  <span class="mf">0.95750813</span>
<span class="mi">1</span>         <span class="n">y</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>     <span class="mf">0.2000</span>  <span class="mf">0.03916822</span>
<span class="mi">2</span>  <span class="n">u1</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="n">y</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>     <span class="mf">0.1003</span>  <span class="mf">0.00332022</span>
</pre></div>
</div>
</div>
<div class="section" id="you-can-acess-some-extra-information-like-the-list-of-all-candidate-regressors">
<h3>You can acess some extra information like the list of all candidate regressors<a class="headerlink" href="#you-can-acess-some-extra-information-like-the-list-of-all-candidate-regressors" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># for now the list is returned as a codification. Here, $0$ is the constant term, $[1001]=y{k-1}, [100n]=y_{k-n}, [200n] = x1_{k-n}, [300n]=x2_{k-n}$ and so on</span>
<span class="n">model</span><span class="o">.</span><span class="n">regressor_code</span>  <span class="c1"># list of all possible regressors given non_degree, n_y and n_x values</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span>   <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1001</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1002</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2001</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2002</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1001</span><span class="p">,</span> <span class="mi">1001</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1002</span><span class="p">,</span> <span class="mi">1001</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2001</span><span class="p">,</span> <span class="mi">1001</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2002</span><span class="p">,</span> <span class="mi">1001</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1002</span><span class="p">,</span> <span class="mi">1002</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2001</span><span class="p">,</span> <span class="mi">1002</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2002</span><span class="p">,</span> <span class="mi">1002</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2001</span><span class="p">,</span> <span class="mi">2001</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2002</span><span class="p">,</span> <span class="mi">2001</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2002</span><span class="p">,</span> <span class="mi">2002</span><span class="p">]])</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">err</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>  <span class="c1"># err values for the selected terms</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">theta</span><span class="p">)</span>  <span class="c1"># estimated parameters for the final model structure</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">0.95750813</span> <span class="mf">0.03916822</span> <span class="mf">0.00332022</span> <span class="mf">0.</span>         <span class="mf">0.</span>         <span class="mf">0.</span>
 <span class="mf">0.</span>         <span class="mf">0.</span>         <span class="mf">0.</span>         <span class="mf">0.</span>         <span class="mf">0.</span>         <span class="mf">0.</span>
 <span class="mf">0.</span>         <span class="mf">0.</span>         <span class="mf">0.</span>        <span class="p">]</span>


<span class="p">[[</span><span class="mf">0.90008672</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.19998879</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">0.10026928</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dev_guide.html" class="btn btn-neutral float-right" title="Contributing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="introduction_to_narmax.html" class="btn btn-neutral" title="A brief introduction to NARMAX models." accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Wilson Rocha, Luan Pascoal, Samuel Oliveira, Samir Martins.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.0.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="_static/language_data.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script type="text/javascript" src="None"></script>
      <script type="text/javascript" src="_static/jquery.fancybox.min.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
  <script type="text/javascript">
    $(function(){
      $('.image-reference').fancybox();
    })
  </script>

</body>
</html>